# 作业提交模板

```
.
├── code/                   # 所有实验代码
└── README.md               # 项目核心文档
```

## 研究目的

探究Glink水位线延迟时间对窗口出发与结果准确性的影响

## 研究内容

深入理解Flink的水位线（Watermark）机制，探究水位线延迟时间对窗口触发延迟和结果计算准确度的影响。进一步研究在乱序数据场景下，如何通过合理设置水位线延迟间，在延迟与计算准确性之间取得平衡。

## 实验

### 实验环境

* 硬件：

- 3节点阿里云服务器
- 4vCPU
- 8G内存
- 内网带宽
- 存储类型
  `集群配置，包括节点数 **(>=3)**、CPU 核数、内存大小、网络带宽、存储类型（SSD / HDD）等。`

* 软件：

- 操作系统: Ubuntu 24.04 
- JDK 版本: openjdk 11
- flink 版本: 1.17.2
- python版本：3.10
- minio 版本：

### 实验负载

#### 数据生成

利用 Flink 内置的`datagen`连接器，使用`events_per_second`参数,控制数据生成速度并生成模拟的`UserEvent`事件流
##### 1. 概述

本实验的数据集并非来自外部静态文件（如 CSV 或日志），而是通过 **Flink DataGen 连接器** 配合自定义的 **Python 映射函数 (MapFunction)** 在内存中实时生成的。

数据生成的核心逻辑封装在 `exp.py` 的 `EventGeneratorMapFunction` 类中，旨在模拟具有随机延迟和迟到特性的用户行为数据流。

##### 2. 数据构建核心流程

数据生成主要分为两个步骤：**基础序列生成** 和 **业务属性模拟**。

##### 第一步：基础序列流 (Source)

利用 Flink SQL 的 `datagen` 连接器生成基础触发流。

* **生成内容**：简单的递增数字序列 (Sequence)。

* **生成速率**：由 `events_per_second` 参数严格控制。

##### 第二步：业务属性模拟 (Map Transformation)

将上述数字序列通过 `EventGeneratorMapFunction` 转换为具有业务含义的 `UserEvent` 对象。每个事件包含以下核心字段的模拟逻辑：

1.  **基准时间 (`base_timestamp`)**：

    * 获取当前的系统物理时间 (System Time) 作为基准。

2.  **事件时间 (`event_time`) - 核心逻辑**：

   * **正常乱序**：在基准时间基础上，减去一个 `0` 到 `max_out_of_orderness_ms` 之间的随机延迟。

    * **迟到数据 (Late Event)**：如果命中迟到概率，会额外再减去一段时长，强制生成早于水位线的时间戳，用于测试 Flink 的迟到丢弃机制。

3.  **用户 ID (`user_id`)**：

    * 在 `1` 到 `100` 之间随机生成整数 (例如: `user-42`)。

4.  **事件类型 (`event_type`)**：

    * 从 `["click", "view", "purchase", "logout"]` 中随机选择。

5.  **金额 (`amount`)**：

    * 生成 `1.0` 到 `500.0` 之间的随机浮点数。
---

##### 3. 数据集控制参数

通过命令行参数可以精准控制生成数据的**速度**、**规模**以及**乱序程度**。

##### A. 流量与规模控制

| 参数名称 (命令行) | 代码变量名 | 作用解释 | 默认值 |
| :--- | :--- | :--- | :--- |
| `--eventsPerSecond` | `events_per_second` | **生成速率**。<br>控制每秒产生多少条数据。数值越大，系统吞吐压力越大。 | 200 |
| `--runDurationMs` | `run_duration_ms` | **数据总量控制**。<br>设定程序运行多久后停止生成数据。例如设为 60000ms，速率 200/s，则总共生成约 12,000 条数据。 | 60000 |


##### B. 时间乱序与数据质量控制 (关键)

这部分参数决定了数据流中时间的“混乱程度”，直接决定了实验中窗口触发的时机和迟到数据的比例。

##### 1. `--maxOutOfOrdernessMs`

* **变量名**：`max_out_of_orderness_ms`

* **含义**：正常的数据乱序范围。

* **解释**：模拟正常的网络延迟。例如设为 5000ms，表示生成的事件时间可能比当前物理时间晚 0~5 秒。这是 Watermark 通常能够容忍的范围。

* **默认值**：5000

##### 2. `--lateEventFraction`

* **变量名**：`late_event_fraction`

* **含义**：迟到数据的比例。

* **解释**：决定了数据集中有多少数据是“严重迟到”的（即人为制造的脏数据）。例如设为 0.5，表示 50% 的数据会被故意伪造为过期数据。

* **默认值**：0.5

##### 3. `--severeLatenessUpperBoundMs`

* **变量名**：`severe_lateness_upper_bound_ms`

* **含义**：严重迟到的追加时长。

* **解释**：对于被判定为“严重迟到”的数据，让它们在“最大乱序时间”的基础上再“旧”多久。

* **计算公式**：

    $$

    迟到事件时间 = 当前时间 - (正常乱序最大值 + 随机严重迟到值)

    $$

* **默认值**：5000

---

##### 4. 参数配置示例

* **测试高并发压力**：

    `--eventsPerSecond 10000`

* **测试大量丢弃数据（高迟到率）**：

    `--lateEventFraction 0.8 --severeLatenessUpperBoundMs 10000`

* **测试完全有序流（无乱序）**：

    `--maxOutOfOrdernessMs 0 --lateEventFraction 0`
##### 5. 部分数据展示：
![数据展示](./image.png)
### 实验步骤

列出执行实验的关键步骤，并对关键步骤进行截图，如 MapReduce / Spark / Flink 部署成功后的进程信息、作业执行成功的信息等，**截图能够通过显示用户账号等个性化信息佐证实验的真实性**。

### 实验结果与分析

使用表格和图表直观呈现结果，并解释结果背后的原因。

### 结论

总结研究的主要发现。

### 分工

尽可能详细地写出每个人的具体工作和贡献度，并按贡献度大小进行排序。